# -*- coding: utf-8 -*-
"""Stress Predict model deployment code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CC0ZeXIaqGnc0h1CFAPqNcVmt_n4RVoj

# Student ID: 2201005

# Import the required packages
"""

import shutil
import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.utils import resample
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from datetime import datetime, time
from keras.models import Sequential
from keras.layers import Dense, Dropout, LSTM, Bidirectional
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
from prettytable import PrettyTable

"""# Google drive Configuration"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)
GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = os.path.join('./Data Science/') # Make sure to update with your student_id and student_id is an integer
GOOGLE_DRIVE_PATH = os.path.join('gdrive', 'MyDrive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)
print('List files: ', os.listdir(GOOGLE_DRIVE_PATH))

"""# Functions to extract the data"""

# Name of the zip file to extract
BaseZipFolderPath=GOOGLE_DRIVE_PATH

# path to extract
BaseZipFolderPath=GOOGLE_DRIVE_PATH

# folder to store the files
input_folderpath=BaseZipFolderPath+'users/'
# Creating the folder names
users = {f"{i:02d}": None for i in range(2, 36)}

for key in users.keys():
    filename = os.path.join(input_folderpath, f"{key}.csv")
    users[key] = pd.read_csv(filename)

# Print the dictionary
print(users)

"""# Function to do the below:


*   Compute the performance of the model.
*   Create the train, valid and test dataset for each user.
*   Create the sliding window.
*   Flatten the data into 2 dimensions.
*   Normalize the flattened data.





"""

# Compute the performance of the model
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

def evaluate_model(true, pred, data_set_type):
    accuracy = (pred == true).mean()
    precision = precision_score(true, pred, average='macro')
    recall = recall_score(true, pred, average='macro')
    f1 = f1_score(true, pred, average='macro')
    confusion = confusion_matrix(true, pred)
    fpr, tpr, thresholds = roc_curve(true, pred)
    roc_auc = auc(fpr, tpr)

    table = PrettyTable()
    table.field_names = ["\033[1mDataset\033[0m", "\033[1mAccuracy\033[0m", "\033[1mPrecision\033[0m", "\033[1mRecall\033[0m", "\033[1mF1 Score\033[0m"]
    if data_set_type.lower() == 'valid':
        table.add_row(["Validation set", f"{accuracy:.4f}", f"{precision:.4f}", f"{recall:.4f}", f"{f1:.4f}"])
    else:
        table.add_row(["Test set", f"{accuracy:.4f}", f"{precision:.4f}", f"{recall:.4f}", f"{f1:.4f}"])

    print(table)
    print("Confusion matrix:\n", confusion)

    plt.figure()
    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver operating characteristic')
    plt.legend(loc="lower right")
    plt.show()

# Create the train, valid and test dataset for each user
def create_the_split(data):
    td_ratio=0.5
    vd_ratio=0.3
    train = int(td_ratio * len(data))
    valid = int(vd_ratio * len(data))
    test = len(data) - train - valid
    
    train_data = data[:train]
    val_data = data[train:train+valid]
    test_data = data[train+valid:]
    
    print('-----------------------------')
    print('Train set count: ' + str(train))
    print('-----------------------------')
    print('Val set count: ' + str(valid))
    print('-----------------------------')
    print('Test set count: ' + str(test))
    print('-----------------------------')
    
    return train_data, val_data, test_data

# Create the train, valid and test dataset for each user
def create_split(X, y):
  td_ratio=0.5
  vd_ratio=0.3

  train = int(td_ratio * len(X))
  valid = int(vd_ratio * len(X))
  test = len(X) - train - valid
      
  # Create train data
  train_data_x = X[:train]
  train_data_y = y[:train]

  # create validation data
  valid_data_x = X[train:train+valid]
  valid_data_y = y[train:train+valid]

  # Create data
  test_data_x = X[train+valid:]
  test_data_y = y[train+valid:]
      
  # Showin the count of each data
  print('----------------------------------')
  print('Train X: ' + str(len(train_data_x)))
  print('----------------------------------')
  print('Train Y : ' + str(len(train_data_y)))
  print('----------------------------------')
  print('Valid X: ' + str(len(valid_data_x)))
  print('----------------------------------')
  print('Valid Y: ' + str(len(valid_data_y)))
  print('----------------------------------')
  print('Test X: ' + str(len(test_data_x)))
  print('----------------------------------')
  print('Test Y: ' + str(len(test_data_y)))
  print('----------------------------------')

  return train_data_x, train_data_y, valid_data_x, valid_data_y, test_data_x, test_data_y

def create_window(users, user, window_size=30, step_size=10):
    # Get the data for the required user
    data = users[user]

    # Set datetime column as index
    data = data.set_index('datetime')

    n_samples = len(data) - window_size + 1
    n_features = data.shape[1] - 1

    # Create an array to hold the windows
    X = np.zeros((n_samples, window_size, n_features))

    # Create an array to hold the labels
    y = np.zeros(n_samples)

    # Segment time series into windows
    for i in range(n_samples):
        X[i] = data.iloc[i:i+window_size, :-1].values
        y[i] = data.iloc[i+window_size-1]['label']

    return X, y

# Flatten the data into 2 dimensions
def flatten_data(train_x, train_y, valid_x, valid_y, test_x, test_y,scaler):    
    train_x_flat_file = np.reshape(train_x, (-1, train_x.shape[2]))     
    valid_x_flat_file = np.reshape(valid_x, (-1, valid_x.shape[2]))
    test_x_flat_file = np.reshape(test_x, (-1, test_x.shape[2]))

    normalized_train_x = scaler.fit_transform(train_x_flat_file)
    normalized_valid_x = scaler.transform(valid_x_flat_file)
    normalized_test_x = scaler.transform(test_x_flat_file)

    # Reshape the normalized data back into 3 dimensions
    normalized_train_x = normalized_train_x.reshape((train_x.shape[0], train_x.shape[1], train_x.shape[2]))
    normalized_valid_x = normalized_valid_x.reshape((valid_x.shape[0], valid_x.shape[1], valid_x.shape[2]))
    normalized_test_x = normalized_test_x.reshape((test_x.shape[0], test_x.shape[1], test_x.shape[2]))

    return normalized_train_x, normalized_valid_x, normalized_test_x

"""# Model 1 start: RandomForestClassifier with hyper parameter tuning"""

def random_forest_classifier_with_hyperparameter_tuning(train_x, train_y, valid_X, valid_y, test_x, test_y):
  # initialize the random forest model
  rf_model = RandomForestClassifier(random_state=42)

  param_grid = {
      'n_estimators': [50, 100],
      'max_depth': [10, 20, 30],
      'min_samples_split': [2, 5, 10],
      'min_samples_leaf': [1, 2, 4],
      'criterion': ['gini']
  }

  # initialize the grid search
  grid_search = GridSearchCV(rf_model, param_grid, cv=5)

  # fit the grid search to the training data
  grid_search.fit(train_x, train_y)

  # print the best hyperparameters
  print("Best hyperparameters:", grid_search.best_params_)

  # predict labels for the valid data using the best model
  valid_pred = grid_search.predict(valid_X)

  # predict labels for the test data using the best model
  test_pred = grid_search.predict(test_x)

  return valid_pred, test_pred

"""# Model 1 End

# Model 2 start: BLSTM
"""

def blstm(train_x, train_y, valid_X, valid_y, test_x, test_y):
  # # define the input shape
  input_shape=(train_x.shape[1], train_x.shape[2])

  # initialize the model
  model = Sequential()

  # add bidirectional LSTM layer
  model.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=input_shape))
  model.add(Dropout(0.5))

  # add another bidirectional LSTM layer
  model.add(Bidirectional(LSTM(64, return_sequences=False)))
  model.add(Dropout(0.5))

  # add output layer
  model.add(Dense(1, activation='sigmoid'))

  # compile the model
  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

  # train the model
  history = model.fit(train_x, train_y, 
                      validation_data=(valid_X, valid_y), 
                      epochs=10, batch_size=64, verbose=1)

  # evaluate the model on the validation data
  valid_loss, valid_acc = model.evaluate(valid_X, valid_y, verbose=0)
     
  # evaluate the model on the test data
  test_loss, test_accuracy = model.evaluate(test_x, test_y, verbose=0)
  # print("Test accuracy:", test_accuracy)

  # make predictions on the validation data
  valid_pred_prob = model.predict(valid_X)
  valid_pred = (valid_pred_prob >= 0.5).astype(int)

  # make predictions on the test data
  test_pred_prob = model.predict(test_x)
  test_pred = (test_pred_prob >= 0.5).astype(int)

  # evaluate the model using precision, recall, and f1 score
  # evaluate_model(test_y, test_pred, 'test')
  return valid_pred, test_pred

"""# Model 2 End

# Execution
"""

# Train and test the model and display the evaluation metrics
def execute1(model,users, no_of_users):
  scaler = StandardScaler()
  cols_to_standardize = ['X', 'Y', 'Z', 'BVP', 'EDA', 'HR', 'IBI_Initial', 'IBI_Interval', 'TEMP']
  count = 0
  if no_of_users == 0:
    print('Pls specify the number of users')
  else:
    for user in users:
      if count < no_of_users:
        count = count + 1
        print('**********************************************************************************************************************')
        print('Executing the model for user: ',user,'\n')
        if model == 'blstm':
          X, y = create_window(users, '04')
          X_train, y_train, X_val, y_val, X_test, y_test = create_split(X, y)
          normalized_train_x, normalized_valid_x, normalized_test_x = flatten_data(X_train, y_train, X_val, y_val, X_test, y_test,scaler)          
          valid_pred, test_pred = blstm(normalized_train_x, y_train, normalized_valid_x, y_val, normalized_test_x, y_test)
          evaluate_model(y_val, valid_pred, 'valid')
          evaluate_model(y_test, test_pred, 'test')
        else:
            # Creating the train, valid and test data for User 2
          train_user2, valid_user2, test_user2 = create_the_split(users[user])
          train_user2_data = train_user2[['X','Y','Z','BVP','EDA','HR','IBI_Initial','IBI_Interval','TEMP']]
          train_user2_label = train_user2['label'].values
          valid_user2_data = valid_user2[['X','Y','Z','BVP','EDA','HR','IBI_Initial','IBI_Interval','TEMP']]
          valid_user2_label = valid_user2['label'].values
          test_user2_data = test_user2[['X','Y','Z','BVP','EDA','HR','IBI_Initial','IBI_Interval','TEMP']]
          test_user2_label = test_user2['label'].values

          train_user2_data.loc[:,cols_to_standardize] = scaler.fit_transform(train_user2_data.loc[:,cols_to_standardize].copy())
          valid_user2_data.loc[:,cols_to_standardize] = scaler.fit_transform(valid_user2_data.loc[:,cols_to_standardize].copy())
          test_user2_data.loc[:,cols_to_standardize] = scaler.fit_transform(test_user2_data.loc[:,cols_to_standardize].copy())
          
          valid_pred, test_pred = random_forest_classifier_with_hyperparameter_tuning(train_user2_data, train_user2_label, valid_user2_data, valid_user2_label, test_user2_data, test_user2_label)
          evaluate_model(valid_user2_label, valid_pred, 'valid')
          evaluate_model(test_user2_label, test_pred, 'test')
      else:
        break
    print('Model results are displayed for ',str(no_of_users),' user(s).')

execute1('blstm',users,1)

execute1('random forest',users,1)

execute1('blstm',users,len(users.keys()))

execute1('random forest',users,len(users.keys()))